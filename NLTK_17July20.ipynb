{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@Author: Rutvik Patel (17BCE0729)\n",
    "#@Date: 17 July 2020\n",
    "#@Description: NLTK fundamentals hands on session; CSE4022 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # use brown, inaugral, book, webtext, wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download() #Only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Now',\n",
       " 'that',\n",
       " 'he',\n",
       " 'knew',\n",
       " 'himself',\n",
       " 'to',\n",
       " 'be',\n",
       " 'self',\n",
       " 'he',\n",
       " 'was',\n",
       " 'free',\n",
       " 'to',\n",
       " 'grok',\n",
       " 'ever',\n",
       " 'closer']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import brown corpus and access the data\n",
    "from nltk.corpus import brown\n",
    "# brown.categories()\n",
    "brown.words(categories = 'science_fiction')[ : 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import inaugral corpus and access the data (1789 to 2017)\n",
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()\n",
    "# inaugural.words(fileids = '2017-Trump.txt')[ : 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'fellow',\n",
       " 'citizens',\n",
       " ':',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'here',\n",
       " 'today',\n",
       " 'humbled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'task',\n",
       " 'before',\n",
       " 'us',\n",
       " ',']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids = '2009-Obama.txt')[ : 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " ':',\n",
       " 'In',\n",
       " 'compliance',\n",
       " 'with',\n",
       " 'a',\n",
       " 'custom',\n",
       " 'as',\n",
       " 'old']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids = '1861-Lincoln.txt')[ : 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chief',\n",
       " 'Justice',\n",
       " 'Roberts',\n",
       " ',',\n",
       " 'President',\n",
       " 'Carter',\n",
       " ',',\n",
       " 'President',\n",
       " 'Clinton',\n",
       " ',',\n",
       " 'President',\n",
       " 'Bush',\n",
       " ',',\n",
       " 'President',\n",
       " 'Obama',\n",
       " ',',\n",
       " 'fellow',\n",
       " 'Americans',\n",
       " ',',\n",
       " 'and',\n",
       " 'people',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " ':',\n",
       " 'Thank',\n",
       " 'you',\n",
       " '.',\n",
       " 'We',\n",
       " ',',\n",
       " 'the',\n",
       " 'citizens',\n",
       " 'of',\n",
       " 'America',\n",
       " ',',\n",
       " 'are',\n",
       " 'now',\n",
       " 'joined',\n",
       " 'in',\n",
       " 'a',\n",
       " 'great',\n",
       " 'national',\n",
       " 'effort',\n",
       " 'to',\n",
       " 'rebuild',\n",
       " 'our',\n",
       " 'country',\n",
       " 'and',\n",
       " 'restore',\n",
       " 'its']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.words(fileids = '2017-Trump.txt')[ : 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firefox.txt',\n",
       " 'grail.txt',\n",
       " 'overheard.txt',\n",
       " 'pirates.txt',\n",
       " 'singles.txt',\n",
       " 'wine.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import webtext and access the data\n",
    "from nltk.corpus import webtext\n",
    "webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 106, '.': 89, 'and': 70, 'the': 65, 'of': 48, 'our': 47, 'will': 43, 'to': 37, 'We': 26, 'we': 24, ...})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleText = \" \".join(inaugural.words(fileids = '2017-Trump.txt')[ : ])\n",
    "tokenFreqDist = nltk.FreqDist(sampleText.split())\n",
    "tokenFreqDist\n",
    "\n",
    "# from collections import Counter\n",
    "# ctr = Counter(sampleText)\n",
    "# ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'their': 10, 'again': 9, 'world': 6, 'great': 6, 'while': 6, 'never': 6, 'right': 5, 'other': 5, 'every': 5, 'Thank': 4, ...})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conditional frequency distribution\n",
    "from nltk.probability import ConditionalFreqDist as cfd\n",
    "tokenCondFreqDist = cfd((len(word), word) for word in sampleText.split()) #(condition index, value) as a tuple\n",
    "tokenCondFreqDist[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
